{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8843ee8-7540-4529-8744-d8ce65bd9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53f62db-9737-4af8-9e32-9ed5030787d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\WINNER\\\\Exports'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1000b5-4ffa-4fdb-ac7b-375e2922e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    device_id   latitude   longitude            timestamp  gyro_x  gyro_y  \\\n",
      "0           1  37.774929 -122.419418  2024-06-01 08:00:00     0.1     0.2   \n",
      "1           1  37.775030 -122.419500  2024-06-01 08:05:00     0.2     0.1   \n",
      "2           1  37.775140 -122.419600  2024-06-01 08:10:00     0.0     0.1   \n",
      "3           1  37.775250 -122.419700  2024-06-01 08:15:00     0.1     0.0   \n",
      "4           1  37.775360 -122.419800  2024-06-01 08:20:00     0.3    -0.1   \n",
      "..        ...        ...         ...                  ...     ...     ...   \n",
      "70          5  48.857160    2.352700  2024-06-01 12:25:00     0.1     0.1   \n",
      "71          5  48.857270    2.352800  2024-06-01 12:30:00     0.2    -0.2   \n",
      "72          5  48.857380    2.352900  2024-06-01 12:35:00    -0.1     0.2   \n",
      "73          5  48.857490    2.353000  2024-06-01 12:40:00     0.0    -0.2   \n",
      "74          5  48.857600    2.353100  2024-06-01 12:45:00     0.1     0.0   \n",
      "\n",
      "    gyro_z    ax    ay    az  \n",
      "0     -0.1  0.01 -0.01  0.03  \n",
      "1     -0.2  0.02 -0.02  0.04  \n",
      "2      0.1  0.03 -0.03  0.02  \n",
      "3     -0.1  0.04 -0.04  0.01  \n",
      "4     -0.2  0.05 -0.05  0.00  \n",
      "..     ...   ...   ...   ...  \n",
      "70     0.1 -0.01  0.00 -0.01  \n",
      "71    -0.2 -0.02  0.01 -0.02  \n",
      "72     0.2 -0.03  0.02 -0.03  \n",
      "73    -0.1 -0.04  0.03 -0.04  \n",
      "74     0.0 -0.05  0.04 -0.05  \n",
      "\n",
      "[75 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "def connect_to_mysql_and_query(user, password, host, database, query):\n",
    "    try:\n",
    "        # Establish connection to MySQL server\n",
    "        conn = mysql.connector.connect(\n",
    "            host=host,          # Your host\n",
    "            user=user,          # Your username\n",
    "            password=password,  # Your password\n",
    "            database=database   # Your database name\n",
    "        )\n",
    "\n",
    "        # Create a cursor object to execute SQL queries\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute the query\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch all rows from the executed query\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        # Get column names from the cursor\n",
    "        columns = [i[0] for i in cursor.description]\n",
    "\n",
    "        # Create a DataFrame from the fetched rows and columns\n",
    "        df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "def export_to_csv(df, file_path):\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def load_csv_to_dataframe(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # MySQL database credentials and query\n",
    "    host = \"localhost\"       # Your host\n",
    "    user = \"root\"            # Your username\n",
    "    password = \"sunDay01@new\"   # Your password\n",
    "    database = \"location_data\"\n",
    "    query = \"SELECT * FROM location_spotted\"\n",
    "\n",
    "    # Connect to MySQL and fetch data\n",
    "    df = connect_to_mysql_and_query(user, password, host, database, query)\n",
    "\n",
    "    if df is not None:\n",
    "        # Export the DataFrame to CSV\n",
    "        csv_file_path = 'Location_output.csv'\n",
    "        export_to_csv(df, csv_file_path)\n",
    "\n",
    "        # Load the CSV file into a new DataFrame\n",
    "        new_df = load_csv_to_dataframe(csv_file_path)\n",
    "\n",
    "        # Print the loaded DataFrame\n",
    "        print(new_df)\n",
    "    else:\n",
    "        print(\"Failed to fetch data from the database.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0348ad-db72-430d-ad18-f8c4cb6d82a6",
   "metadata": {},
   "source": [
    "**Database Interaction Script**\n",
    "\n",
    "This script performs the following tasks:\n",
    "\n",
    "1. **Connects to a Database**: It establishes a connection to a MySQL database, which serves as a structured storage for various types of data.\n",
    "\n",
    "2. **Fetches Data**: After connecting, it retrieves information from a specific table within the database. This data could encompass a wide range of information, such as names, locations, or numerical values.\n",
    "\n",
    "3. **Converts to CSV**: Upon fetching the data, the script transforms it into a CSV (Comma-Separated Values) file format. CSV files resemble spreadsheets and can be easily opened and viewed using programs like Microsoft Excel or Google Sheets.\n",
    "\n",
    "4. **Loads Data from CSV**: Subsequently, it reads the CSV file, loading the data back into a Python-friendly format. This step ensures that the data is easily manipulable and accessible within a Python environment.\n",
    "\n",
    "5. **Displays Data**: Finally, the script presents the retrieved data in a human-readable format, typically resembling a table, making it easy for users to comprehend and analyze.\n",
    "\n",
    "In essence, this script facilitates the process of acquiring data from a database, storing it in a file format, and then presenting it in a user-friendly manner, akin to how information is organized and presented in spreadsheet applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07dcea-6f80-4471-ae56-f597df832ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4c1bf2-89db-4973-8e4c-38f3deccfb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_file_path = 'Location_output.csv'\n",
    "df=pd.read_csv(csv_file_path)\n",
    "df1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ba35b8-43ed-4f35-b190-0746a6f43f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>37.774929</td>\n",
       "      <td>-122.419418</td>\n",
       "      <td>2024-06-01 08:00:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37.775030</td>\n",
       "      <td>-122.419500</td>\n",
       "      <td>2024-06-01 08:05:00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>37.775140</td>\n",
       "      <td>-122.419600</td>\n",
       "      <td>2024-06-01 08:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>37.775250</td>\n",
       "      <td>-122.419700</td>\n",
       "      <td>2024-06-01 08:15:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>37.775360</td>\n",
       "      <td>-122.419800</td>\n",
       "      <td>2024-06-01 08:20:00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5</td>\n",
       "      <td>48.857160</td>\n",
       "      <td>2.352700</td>\n",
       "      <td>2024-06-01 12:25:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5</td>\n",
       "      <td>48.857270</td>\n",
       "      <td>2.352800</td>\n",
       "      <td>2024-06-01 12:30:00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5</td>\n",
       "      <td>48.857380</td>\n",
       "      <td>2.352900</td>\n",
       "      <td>2024-06-01 12:35:00</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5</td>\n",
       "      <td>48.857490</td>\n",
       "      <td>2.353000</td>\n",
       "      <td>2024-06-01 12:40:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5</td>\n",
       "      <td>48.857600</td>\n",
       "      <td>2.353100</td>\n",
       "      <td>2024-06-01 12:45:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    device_id   latitude   longitude            timestamp  gyro_x  gyro_y  \\\n",
       "0           1  37.774929 -122.419418  2024-06-01 08:00:00     0.1     0.2   \n",
       "1           1  37.775030 -122.419500  2024-06-01 08:05:00     0.2     0.1   \n",
       "2           1  37.775140 -122.419600  2024-06-01 08:10:00     0.0     0.1   \n",
       "3           1  37.775250 -122.419700  2024-06-01 08:15:00     0.1     0.0   \n",
       "4           1  37.775360 -122.419800  2024-06-01 08:20:00     0.3    -0.1   \n",
       "..        ...        ...         ...                  ...     ...     ...   \n",
       "70          5  48.857160    2.352700  2024-06-01 12:25:00     0.1     0.1   \n",
       "71          5  48.857270    2.352800  2024-06-01 12:30:00     0.2    -0.2   \n",
       "72          5  48.857380    2.352900  2024-06-01 12:35:00    -0.1     0.2   \n",
       "73          5  48.857490    2.353000  2024-06-01 12:40:00     0.0    -0.2   \n",
       "74          5  48.857600    2.353100  2024-06-01 12:45:00     0.1     0.0   \n",
       "\n",
       "    gyro_z    ax    ay    az  \n",
       "0     -0.1  0.01 -0.01  0.03  \n",
       "1     -0.2  0.02 -0.02  0.04  \n",
       "2      0.1  0.03 -0.03  0.02  \n",
       "3     -0.1  0.04 -0.04  0.01  \n",
       "4     -0.2  0.05 -0.05  0.00  \n",
       "..     ...   ...   ...   ...  \n",
       "70     0.1 -0.01  0.00 -0.01  \n",
       "71    -0.2 -0.02  0.01 -0.02  \n",
       "72     0.2 -0.03  0.02 -0.03  \n",
       "73    -0.1 -0.04  0.03 -0.04  \n",
       "74     0.0 -0.05  0.04 -0.05  \n",
       "\n",
       "[75 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "284ece6c-f8b3-49b4-8361-a9ae946945db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb23fd41-d54c-477f-8c48-582b6cdeb374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_ adding :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e38772-3d9d-4418-843d-71ea8d004372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "def calculate_geodesic_distance(df):\n",
    "    \"\"\"\n",
    "    Calculates the geodesic distance between consecutive latitude and longitude\n",
    "    points for each device in the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'latitude' and 'longitude' columns.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'geodesic_distance' containing the distances.\n",
    "    \"\"\"\n",
    "    df['geodesic_distance'] = np.nan\n",
    "    \n",
    "    for device_id, group in df.groupby('device_id'):\n",
    "        previous_point = None\n",
    "        distances = []\n",
    "        \n",
    "        for index, row in group.iterrows():\n",
    "            current_point = (row['latitude'], row['longitude'])\n",
    "            \n",
    "            if previous_point is not None:\n",
    "                distance = geodesic(previous_point, current_point).kilometers\n",
    "                distances.append(distance)\n",
    "            else:\n",
    "                distances.append(0)\n",
    "            \n",
    "            previous_point = current_point\n",
    "        \n",
    "        df.loc[group.index, 'geodesic_distance'] = distances\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('data.csv')\n",
    "# df = preprocess_data(df)\n",
    "# df = calculate_geodesic_distance(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ae0e5-6388-488d-a4c8-d9e7e0d27b50",
   "metadata": {},
   "source": [
    "**Geodesic Distance Calculation**\n",
    "\n",
    "**Inputs**: It takes a DataFrame as input, which should contain columns for latitude and longitude.\n",
    "\n",
    "**Outputs**: The function returns a DataFrame with an additional column called 'geodesic_distance', which contains the calculated distances.\n",
    "\n",
    "**Process**: For each device in the DataFrame, the function iterates through the latitude and longitude points. It calculates the distance between each pair of consecutive points using the geodesic distance formula provided by the Geopy library. The calculated distances are then stored in the 'geodesic_distance' column of the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d77e9c08-58c6-4def-b3e4-3809796fe4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_processing of Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "786ffc8f-bae3-476a-ab4a-87a93391cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Step 1: Handling Missing Values using Imputer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    numerical_cols = ['latitude', 'longitude', 'gyro_x', 'gyro_y', 'gyro_z', 'ax', 'ay', 'az',\n",
    "                      'geodesic_distance', 'dwells', 'trips', 'hour', 'minute', 'second',\n",
    "                      'trip_duration', 'dwell_duration', 'gyro_magnitude', 'accel_magnitude',\n",
    "                      'gyro_x_lag_1', 'gyro_y_lag_1', 'gyro_z_lag_1', 'ax_lag_1', 'ay_lag_1', 'az_lag_1',\n",
    "                      'gyro_x_lag_2', 'gyro_y_lag_2', 'gyro_z_lag_2', 'ax_lag_2', 'ay_lag_2', 'az_lag_2',\n",
    "                      'gyro_x_lag_3', 'gyro_y_lag_3', 'gyro_z_lag_3', 'ax_lag_3', 'ay_lag_3', 'az_lag_3']\n",
    "    df[numerical_cols] = imputer.fit_transform(df[numerical_cols])\n",
    "\n",
    "    # Step 2: Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    numerical_cols_no_timestamp = [col for col in numerical_cols if col != 'timestamp']\n",
    "    df[numerical_cols_no_timestamp] = scaler.fit_transform(df[numerical_cols_no_timestamp])\n",
    "\n",
    "    # Step 3: Feature Engineering - Calculate Magnitudes\n",
    "    df['gyro_magnitude'] = np.sqrt(df['gyro_x']**2 + df['gyro_y']**2 + df['gyro_z']**2)\n",
    "    df['accel_magnitude'] = np.sqrt(df['ax']**2 + df['ay']**2 + df['az']**2)\n",
    "\n",
    "    # Step 4: Handling Sequential Data - Create Lag Features\n",
    "    for lag in range(1, 4):\n",
    "        df[f'gyro_x_lag_{lag}'] = df['gyro_x'].shift(lag)\n",
    "        df[f'gyro_y_lag_{lag}'] = df['gyro_y'].shift(lag)\n",
    "        df[f'gyro_z_lag_{lag}'] = df['gyro_z'].shift(lag)\n",
    "        df[f'ax_lag_{lag}'] = df['ax'].shift(lag)\n",
    "        df[f'ay_lag_{lag}'] = df['ay'].shift(lag)\n",
    "        df[f'az_lag_{lag}'] = df['az'].shift(lag)\n",
    "\n",
    "    # Step 5: Handling Missing Values After Lag Features Creation\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('data.csv')\n",
    "# preprocessed_df = preprocess_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade8af29-3939-4967-bbd2-873793e0a7af",
   "metadata": {},
   "source": [
    "**Data Preprocessing for Analysis**\n",
    "\n",
    "This code prepares data for analysis by:\n",
    "\n",
    "1. **Handling Missing Values**: It fills in missing values in the data using a method called imputation, which helps in making sure the analysis isn't affected by missing information.\n",
    "\n",
    "2. **Scaling Features**: It adjusts the scale of different features (like latitude, longitude, etc.) so that they all have similar importance in the analysis. Imagine it like making sure all ingredients in a recipe are measured using the same unit.\n",
    "\n",
    "3. **Creating New Features**: It calculates new features based on existing ones. For example, it calculates the overall movement intensity from separate measurements of movement in different directions.\n",
    "\n",
    "4. **Handling Sequential Data**: It accounts for the sequence of events in the data. It creates new features by looking at past data points, similar to how weather forecasts consider past weather patterns.\n",
    "\n",
    "5. **Ensuring Data Completeness**: It ensures that there are no gaps or missing values in the data after creating new features.\n",
    "\n",
    "Overall, this code prepares the data so that it's ready for further analysis, like identifying patterns or making predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3743a97-1aa7-454f-bb85-4b4a3719cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trips and Dwell functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68fbd3c-3726-4ebb-b507-b107c60b0e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36708849-0821-4af1-9786-05910c9ad85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def identify_trips_dwells(df,MOVEMENT_DISTANCE_THRESHOLD,DWELL_TIME_THRESHOLD):\n",
    "    trips = []\n",
    "    dwells = []\n",
    "    current_trip = []\n",
    "    current_dwell = []\n",
    "    \n",
    "    for device_id, group in df.groupby('device_id'):\n",
    "        previous_point = None\n",
    "        previous_row = None\n",
    "        for index, row in group.iterrows():\n",
    "            current_point = (row['latitude'], row['longitude'])\n",
    "            if previous_point is not None:\n",
    "                distance = geodesic(previous_point, current_point).kilometers\n",
    "                time_difference = (row['timestamp'] - previous_row['timestamp']).total_seconds()\n",
    "                \n",
    "                if distance < MOVEMENT_DISTANCE_THRESHOLD:\n",
    "                    if time_difference > DWELL_TIME_THRESHOLD:\n",
    "                        current_dwell.append(row)\n",
    "                    else:\n",
    "                        if current_dwell:\n",
    "                            dwells.append(current_dwell)\n",
    "                            current_dwell = []\n",
    "                else:\n",
    "                    if current_trip:\n",
    "                        trips.append(current_trip)\n",
    "                    current_trip = [row]\n",
    "            else:\n",
    "                current_trip = [row]\n",
    "            \n",
    "            previous_point = current_point\n",
    "            previous_row = row\n",
    "        \n",
    "        if current_trip:\n",
    "            trips.append(current_trip)\n",
    "        if current_dwell:\n",
    "            dwells.append(current_dwell)\n",
    "    \n",
    "    return trips, dwells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60209d5c-5602-4364-a1aa-4bd0b4b8174a",
   "metadata": {},
   "source": [
    "**Identifying Trips and Dwells from Movement Data**\n",
    "\n",
    "This function helps in identifying trips and dwells (periods of no movement) from movement data. Here's what it does:\n",
    "\n",
    "- **Inputs**: It takes a DataFrame containing movement data, along with thresholds for movement distance and dwell time.\n",
    "\n",
    "- **Outputs**: The function returns lists of trips and dwells identified from the data.\n",
    "\n",
    "- **Process**:\n",
    "  - It iterates through the data grouped by device ID.\n",
    "  - For each device, it analyzes consecutive points to determine whether they constitute a trip or a dwell.\n",
    "  - If the distance between consecutive points is less than a threshold and the time difference between them is greater than a dwell time threshold, it considers it a dwell.\n",
    "  - If the distance is greater than the movement distance threshold, it considers it a trip.\n",
    "  - It collects all trips and dwells identified for each device and returns them.\n",
    "\n",
    "- **Example Usage**: This function can be used to understand movement patterns, such as identifying when a device is stationary (dwells) or in motion (trips) based on its location data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3c13150-674d-4d5b-97a8-e9d6fedd969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_dwells_and_trips(df):\n",
    "    # Assuming df contains columns: device_id, timestamp, latitude, longitude\n",
    "    \n",
    "    # Sort the DataFrame by device_id and timestamp\n",
    "    df.sort_values(by=['device_id', 'timestamp'], inplace=True)\n",
    "    \n",
    "    # Initialize dwell and trip columns with zeros\n",
    "    df['dwells'] = 0\n",
    "    df['trips'] = 0\n",
    "    \n",
    "    # Iterate through each device_id group\n",
    "    for device_id, group in df.groupby('device_id'):\n",
    "        # Calculate time difference between consecutive timestamps\n",
    "        time_diff = group['timestamp'].diff().dt.total_seconds()\n",
    "        \n",
    "        # Identify consecutive timestamps with time difference greater than a threshold (e.g., 300 seconds)\n",
    "        dwell_indices = group.index[time_diff > 300]\n",
    "        \n",
    "        # Assign dwell values to the dwell column\n",
    "        df.loc[dwell_indices, 'dwells'] = 1\n",
    "        \n",
    "        # Assign trip values to the trip column\n",
    "        if len(dwell_indices) > 0:\n",
    "            trip_indices = dwell_indices - 1\n",
    "            df.loc[trip_indices, 'trips'] = 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df = ... # Your DataFrame with data similar to Location_spotted table\n",
    "# df_with_dwells_and_trips = add_dwells_and_trips(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d512a8-9a94-4f6b-a92f-a6565efc2af1",
   "metadata": {},
   "source": [
    "**Adding Dwells and Trips to Movement Data**\n",
    "\n",
    "This function enhances movement data by adding information about dwells (periods of no movement) and trips (periods of movement). Here's what it does:\n",
    "\n",
    "- **Inputs**: It takes a DataFrame containing movement data, typically with columns like device ID, timestamp, latitude, and longitude.\n",
    "\n",
    "- **Outputs**: The function returns the same DataFrame with additional columns indicating dwells and trips.\n",
    "\n",
    "- **Process**:\n",
    "  - It first sorts the DataFrame by device ID and timestamp to ensure sequential processing.\n",
    "  - Then, it initializes columns for dwells and trips with zeros.\n",
    "  - Next, it iterates through each group of data based on device ID.\n",
    "  - For each group, it calculates the time difference between consecutive timestamps.\n",
    "  - It identifies timestamps with time differences greater than a predefined threshold (e.g., 300 seconds) as dwell points.\n",
    "  - It marks these dwell points with a value of 1 in the 'dwells' column.\n",
    "  - It also identifies the points just before dwell points as trip points and marks them with a value of 1 in the 'trips' column.\n",
    "  - Finally, it returns the DataFrame with added dwells and trips information.\n",
    "\n",
    "- **Example Usage**: This function can be used to understand movement patterns in data, like identifying periods of no movement (dwells) and periods of movement (trips) based on timestamps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5641bf0b-d5c2-4673-a8dc-92d5e2bbc799",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_spans(trips, dwells):\n",
    "    trip_durations = []\n",
    "    dwell_durations = []\n",
    "    \n",
    "    for trip in trips:\n",
    "        start_time = trip[0]['timestamp']\n",
    "        end_time = trip[-1]['timestamp']\n",
    "        duration = (end_time - start_time).total_seconds()\n",
    "        trip_durations.append(duration)\n",
    "        \n",
    "    for dwell in dwells:\n",
    "        start_time = dwell[0]['timestamp']\n",
    "        end_time = dwell[-1]['timestamp']\n",
    "        duration = (end_time - start_time).total_seconds()\n",
    "        dwell_durations.append(duration)\n",
    "    \n",
    "    return trip_durations, dwell_durations\n",
    "\n",
    "def add_spans_to_df(df, trip_durations, dwell_durations):\n",
    "    df['trip_duration'] = np.nan\n",
    "    df['dwell_duration'] = np.nan\n",
    "    \n",
    "    trip_idx = 0\n",
    "    dwell_idx = 0\n",
    "    \n",
    "    for device_id, group in df.groupby('device_id'):\n",
    "        for index, row in group.iterrows():\n",
    "            if trip_idx < len(trip_durations):\n",
    "                df.at[index, 'trip_duration'] = trip_durations[trip_idx]\n",
    "                trip_idx += 1\n",
    "            if dwell_idx < len(dwell_durations):\n",
    "                df.at[index, 'dwell_duration'] = dwell_durations[dwell_idx]\n",
    "                dwell_idx += 1\n",
    "                \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b44c41-d54b-45fb-82f5-6891a6601903",
   "metadata": {},
   "source": [
    "**Evaluating Trip and Dwell Durations**\r\n",
    "\r\n",
    "These functions help in evaluating the durations of trips and dwells identified from movement data. Here's what they do:\r\n",
    "\r\n",
    "- **`evaluate_spans(trips, dwells)`:**\r\n",
    "  - This function takes lists of trips and dwells as input.\r\n",
    "  - It calculates the duration of each trip and dwell by finding the difference between the start and end times.\r\n",
    "  - It returns lists containing the durations of all trips and dwells.\r\n",
    "\r\n",
    "- **`add_spans_to_df(df, trip_durations, dwell_durations)`:**\r\n",
    "  - This function adds trip and dwell durations to the DataFrame containing movement data.\r\n",
    "  - It initializes columns for trip and dwell durations with NaN values.\r\n",
    "  - It iterates through the DataFrame grouped by device ID.\r\n",
    "  - For each row in the DataFrame, it assigns the corresponding trip and dwell durations from the lists to the respective columns.\r\n",
    "  - It returns the DataFrame with added trip and dwell duration information.\r\n",
    "\r\n",
    "These functions provide valuable insights into the durations of trips and dwells, helping in understanding movement patterns over time in the data.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386bfa0c-6c17-4cd1-9726-9c25325023ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c8b77f8-04a3-4089-b927-5cba283b28ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Step 2: Timestamp Processing\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['minute'] = df['timestamp'].dt.minute\n",
    "df['second'] = df['timestamp'].dt.second\n",
    "# Example usage:\n",
    "# Load your data into a DataFrame\n",
    "# df = pd.read_csv('data.csv')\n",
    "df = calculate_geodesic_distance(df)\n",
    "# Identify trips and dwells\n",
    "trips, dwells = identify_trips_dwells(df,5 * 60 ,0.1)\n",
    "\n",
    "# Evaluate spans\n",
    "trip_durations, dwell_durations = evaluate_spans(trips, dwells)\n",
    "\n",
    "# Add spans to DataFrame\n",
    "df = add_spans_to_df(df, trip_durations, dwell_durations)\n",
    "\n",
    "df = add_dwells_and_trips(df)\n",
    "\n",
    "# Preprocess the data\n",
    "\n",
    "# Now the DataFrame `df` contains the trip and dwell durations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a4c61-2c59-432c-b05c-fe2d8d81dc74",
   "metadata": {},
   "source": [
    "**Step 1: Loading Data**\n",
    "Load your data into a DataFrame using `pd.read_csv('data.csv')`.\n",
    "\n",
    "**Step 2: Preprocessing Timestamps**\n",
    "Process the 'timestamp' column to convert it into datetime format and extract hour, minute, and second information using the following code:\n",
    "```python\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['minute'] = df['timestamp'].dt.minute\n",
    "df['second'] = df['timestamp'].dt.second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d8a5346-a6c6-4c9b-b1e4-fbfe7be73820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('check', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe70be16-1160-4913-8766-4163df2b1704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id                     int64\n",
       "latitude                    float64\n",
       "longitude                   float64\n",
       "timestamp            datetime64[ns]\n",
       "gyro_x                      float64\n",
       "gyro_y                      float64\n",
       "gyro_z                      float64\n",
       "ax                          float64\n",
       "ay                          float64\n",
       "az                          float64\n",
       "geodesic_distance           float64\n",
       "dwells                        int64\n",
       "trips                         int64\n",
       "hour                          int32\n",
       "minute                        int32\n",
       "second                        int32\n",
       "trip_duration               float64\n",
       "dwell_duration              float64\n",
       "gyro_magnitude              float64\n",
       "accel_magnitude             float64\n",
       "gyro_x_lag_1                float64\n",
       "gyro_y_lag_1                float64\n",
       "gyro_z_lag_1                float64\n",
       "ax_lag_1                    float64\n",
       "ay_lag_1                    float64\n",
       "az_lag_1                    float64\n",
       "gyro_x_lag_2                float64\n",
       "gyro_y_lag_2                float64\n",
       "gyro_z_lag_2                float64\n",
       "ax_lag_2                    float64\n",
       "ay_lag_2                    float64\n",
       "az_lag_2                    float64\n",
       "gyro_x_lag_3                float64\n",
       "gyro_y_lag_3                float64\n",
       "gyro_z_lag_3                float64\n",
       "ax_lag_3                    float64\n",
       "ay_lag_3                    float64\n",
       "az_lag_3                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e1e556f-bec1-427e-b320-2ac6dd31d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7465fee6-da4c-45d4-9e5f-ae7bd0222c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id                     int64\n",
       "latitude                    float64\n",
       "longitude                   float64\n",
       "timestamp            datetime64[ns]\n",
       "gyro_x                      float64\n",
       "gyro_y                      float64\n",
       "gyro_z                      float64\n",
       "ax                          float64\n",
       "ay                          float64\n",
       "az                          float64\n",
       "geodesic_distance           float64\n",
       "dwells                      float64\n",
       "trips                       float64\n",
       "hour                        float64\n",
       "minute                      float64\n",
       "second                      float64\n",
       "trip_duration               float64\n",
       "dwell_duration              float64\n",
       "gyro_magnitude              float64\n",
       "accel_magnitude             float64\n",
       "gyro_x_lag_1                float64\n",
       "gyro_y_lag_1                float64\n",
       "gyro_z_lag_1                float64\n",
       "ax_lag_1                    float64\n",
       "ay_lag_1                    float64\n",
       "az_lag_1                    float64\n",
       "gyro_x_lag_2                float64\n",
       "gyro_y_lag_2                float64\n",
       "gyro_z_lag_2                float64\n",
       "ax_lag_2                    float64\n",
       "ay_lag_2                    float64\n",
       "az_lag_2                    float64\n",
       "gyro_x_lag_3                float64\n",
       "gyro_y_lag_3                float64\n",
       "gyro_z_lag_3                float64\n",
       "ax_lag_3                    float64\n",
       "ay_lag_3                    float64\n",
       "az_lag_3                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c22392e-d7de-4462-adc4-5012734b9a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107d4e6-346c-4985-b574-6d853c4edd06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ce06c-0e4f-46a1-b438-6444e21b0fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bc8c0e2-a301-4077-9a2b-ae6834f1b1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude Mean Squared Error: 3.413989233401187e-05\n",
      "Latitude Mean Squared Error: 0.0024221155372089434\n",
      "Dwell Accuracy: 1.0\n",
      "Trips Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Load the preprocessed data\n",
    "\n",
    "# Split the data into features (X) and targets (y)\n",
    "X = df.drop(columns=['longitude', 'latitude', 'dwells', 'trips', 'timestamp'])\n",
    "y_longitude = df['longitude']\n",
    "y_latitude = df['latitude']\n",
    "y_dwell = df['dwells']\n",
    "y_trips = df['trips']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_longitude_train, y_longitude_test, y_latitude_train, y_latitude_test, \\\n",
    "y_dwell_train, y_dwell_test, y_trips_train, y_trips_test = train_test_split(X, y_longitude, y_latitude, y_dwell, y_trips, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train regression models to predict longitude and latitude\n",
    "regressor_longitude = RandomForestRegressor(random_state=42)\n",
    "regressor_longitude.fit(X_train, y_longitude_train)\n",
    "\n",
    "regressor_latitude = RandomForestRegressor(random_state=42)\n",
    "regressor_latitude.fit(X_train, y_latitude_train)\n",
    "\n",
    "# Train classification models to predict dwell and trips\n",
    "classifier_dwell = RandomForestClassifier(random_state=42)\n",
    "classifier_dwell.fit(X_train, y_dwell_train)\n",
    "\n",
    "classifier_trips = RandomForestClassifier(random_state=42)\n",
    "classifier_trips.fit(X_train, y_trips_train)\n",
    "\n",
    "# Predictions\n",
    "y_longitude_pred = regressor_longitude.predict(X_test)\n",
    "y_latitude_pred = regressor_latitude.predict(X_test)\n",
    "y_dwell_pred = classifier_dwell.predict(X_test)\n",
    "y_trips_pred = classifier_trips.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse_longitude = mean_squared_error(y_longitude_test, y_longitude_pred)\n",
    "mse_latitude = mean_squared_error(y_latitude_test, y_latitude_pred)\n",
    "accuracy_dwell = accuracy_score(y_dwell_test, y_dwell_pred)\n",
    "accuracy_trips = accuracy_score(y_trips_test, y_trips_pred)\n",
    "\n",
    "print(\"Longitude Mean Squared Error:\", mse_longitude)\n",
    "print(\"Latitude Mean Squared Error:\", mse_latitude)\n",
    "print(\"Dwell Accuracy:\", accuracy_dwell)\n",
    "print(\"Trips Accuracy:\", accuracy_trips)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fe3bef-463c-457a-b852-2ab6b3d2e1c2",
   "metadata": {},
   "source": [
    "**Model Training and Evaluation**\n",
    "\n",
    "This code trains machine learning models to predict longitude, latitude, dwells, and trips based on preprocessed data. Here's what it does:\n",
    "\n",
    "- **Loading Data**: The preprocessed data is loaded into a DataFrame `df`.\n",
    "\n",
    "- **Splitting Data**: The data is split into features (`X`) and targets (`y`) for longitude, latitude, dwells, and trips.\n",
    "\n",
    "- **Training and Testing Sets**: The data is further split into training and testing sets using `train_test_split()` from the scikit-learn library.\n",
    "\n",
    "- **Regression Models**: Random Forest Regression models are trained to predict longitude and latitude.\n",
    "\n",
    "- **Classification Models**: Random Forest Classification models are trained to predict dwells and trips.\n",
    "\n",
    "- **Predictions**: The trained models are used to make predictions on the testing data.\n",
    "\n",
    "- **Evaluation**: The Mean Squared Error (MSE) is calculated for longitude and latitude predictions. The accuracy score is calculated for dwell and trips predictions.\n",
    "\n",
    "- **Printed Results**: The MSE for longitude and latitude predictions, and the accuracy scores for dwell and trips predictions are printed for evaluation.\n",
    "\n",
    "This code helps in building machine learning models to predict location and movement patterns based on historical data, and it evaluates the performance of these models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d75b8-1032-41fb-9196-fddfb7e72df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d6498-16c8-4747-91e7-47699cf77c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5da96fa1-8d27-46ae-8796-1795e5b85834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 187ms/step - loss: 1.2961 - val_loss: 1.1427\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1525 - val_loss: 1.0892\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0373 - val_loss: 1.0468\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.9397 - val_loss: 1.0131\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8580 - val_loss: 0.9880\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7840 - val_loss: 0.9700\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7179 - val_loss: 0.9601\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6652 - val_loss: 0.9551\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6104 - val_loss: 0.9497\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5643 - val_loss: 0.9440\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5210 - val_loss: 0.9397\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4802 - val_loss: 0.9365\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4393 - val_loss: 0.9313\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4071 - val_loss: 0.9239\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3689 - val_loss: 0.9078\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3382 - val_loss: 0.8887\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3092 - val_loss: 0.8688\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2811 - val_loss: 0.8477\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2577 - val_loss: 0.8258\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.2355 - val_loss: 0.8045\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.2153 - val_loss: 0.7829\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1961 - val_loss: 0.7632\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1798 - val_loss: 0.7447\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1655 - val_loss: 0.7296\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1495 - val_loss: 0.7120\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1364 - val_loss: 0.6955\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.1241 - val_loss: 0.6808\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.1134 - val_loss: 0.6647\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1036 - val_loss: 0.6485\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0935 - val_loss: 0.6343\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0855 - val_loss: 0.6176\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0783 - val_loss: 0.5998\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0712 - val_loss: 0.5828\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0655 - val_loss: 0.5667\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0599 - val_loss: 0.5523\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0547 - val_loss: 0.5383\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0506 - val_loss: 0.5254\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0462 - val_loss: 0.5168\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0425 - val_loss: 0.5110\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0392 - val_loss: 0.5050\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0360 - val_loss: 0.5008\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0333 - val_loss: 0.4952\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0308 - val_loss: 0.4888\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0284 - val_loss: 0.4822\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.0264 - val_loss: 0.4749\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0245 - val_loss: 0.4693\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0223 - val_loss: 0.4666\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0210 - val_loss: 0.4652\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.0194 - val_loss: 0.4639\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0180 - val_loss: 0.4627\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3473\n",
      "Loss: 0.3472746014595032\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "# Assume X_train, X_test, y_train_longitude, y_test_longitude, y_train_latitude, y_test_latitude, y_train_dwell, y_test_dwell, y_train_trips, y_test_trips are already prepared\n",
    "\n",
    "# 2. Define the Neural Network Architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(4))  # Output layer with 4 neurons for longitude, latitude, dwell, and trips\n",
    "\n",
    "# 3. Compile the Model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# 4. Train the Model\n",
    "# 4. Train the Model\n",
    "model.fit(X_train, [y_longitude_train, y_latitude_train, y_dwell_train, y_trips_train], epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 5. Evaluate the Model\n",
    "loss = model.evaluate(X_test, [y_longitude_test, y_latitude_test, y_dwell_test, y_trips_test])\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ad1d4-a020-45db-9009-54397ad76414",
   "metadata": {},
   "source": [
    "**Neural Network for Predictions**\n",
    "\n",
    "This code utilizes a neural network to predict longitude, latitude, dwells, and trips based on preprocessed data. Here's what each step does:\n",
    "\n",
    "1. **Data Preprocessing**: The data is assumed to be preprocessed and split into training and testing sets (`X_train`, `X_test`, `y_train_longitude`, `y_test_longitude`, `y_train_latitude`, `y_test_latitude`, `y_train_dwell`, `y_test_dwell`, `y_train_trips`, `y_test_trips`).\n",
    "\n",
    "2. **Define Neural Network Architecture**: The neural network model is defined using the Keras library. It consists of three layers: two hidden layers with 64 and 32 neurons respectively, and an output layer with 4 neurons for longitude, latitude, dwell, and trips prediction.\n",
    "\n",
    "3. **Compile the Model**: The model is compiled with 'mean_squared_error' as the loss function and 'adam' as the optimizer.\n",
    "\n",
    "4. **Train the Model**: The model is trained using the training data for 50 epochs with a batch size of 32 and a validation split of 0.2 (20% of training data used for validation).\n",
    "\n",
    "5. **Evaluate the Model**: The trained model is evaluated using the testing data, and the loss is printed as the evaluation metric.\n",
    "\n",
    "This code facilitates the use of a neural network to predict location coordinates and movement patterns based on historical data, and it provides insight into the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29859c9b-3e56-442a-b17d-333e118fcf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ea002-32fa-4025-a0f8-bce8d45da446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511265fd-1dad-4ecf-ade9-b3a7d68bcd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf614c30-d263-4735-bc40-965774926f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
